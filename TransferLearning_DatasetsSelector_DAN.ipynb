{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4898bf7d",
   "metadata": {},
   "source": [
    "# Transfer Learning con MobileNetV2\n",
    "## Clasificación Binaria Seleccionable\n",
    "\n",
    "Este cuaderno permite elegir uno de los siguientes datasets binarios integrados en `tensorflow_datasets` y entrenar un clasificador basado en MobileNetV2:\n",
    "\n",
    "1. **horses_or_humans**\n",
    "2. **cats_vs_dogs**\n",
    "3. **smile** (atributo *Smiling* del dataset CelebA)\n",
    "4. **covid_chestxray** (radiografías de tórax normales vs neumonía/COVID‑19)\n",
    "\n",
    "> Selecciona el dataset en la celda siguiente y ejecuta todo el notebook para entrenar, evaluar la precisión y probar con imágenes propias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b795c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow tensorflow-datasets ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ed0bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Selección de dataset { run: 'auto' }\n",
    "DATASET_NAME = 'horses_or_humans' #@param ['horses_or_humans', 'cats_vs_dogs', 'smile', 'covid_chestxray']\n",
    "IMG_SIZE = 160\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecbc21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "print(f'Dataset seleccionado: {DATASET_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edebf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(name):\n",
    "    if name == 'horses_or_humans':\n",
    "        splits = ['train[:70%]', 'train[70%:85%]', 'train[85%:]']\n",
    "        train_ds, val_ds, test_ds = tfds.load(\n",
    "            'horses_or_humans',\n",
    "            split=splits,\n",
    "            as_supervised=True,\n",
    "        )\n",
    "    elif name == 'cats_vs_dogs':\n",
    "        splits = ['train[:80%]', 'train[80%:90%]', 'train[90%:]']\n",
    "        train_ds, val_ds, test_ds = tfds.load(\n",
    "            'cats_vs_dogs',\n",
    "            split=splits,\n",
    "            as_supervised=True,\n",
    "        )\n",
    "    elif name == 'smile':\n",
    "        # CelebA: usamos el atributo 'Smiling' como etiqueta binaria\n",
    "        splits = ['train[:80%]', 'train[80%:90%]', 'train[90%:]']\n",
    "        def map_smile(example):\n",
    "            image = example['image']\n",
    "            label = example['attributes']['Smiling']\n",
    "            return image, label\n",
    "        train_ds = tfds.load('celeb_a', split=splits[0]).map(map_smile)\n",
    "        val_ds   = tfds.load('celeb_a', split=splits[1]).map(map_smile)\n",
    "        test_ds  = tfds.load('celeb_a', split=splits[2]).map(map_smile)\n",
    "    else:  # covid_chestxray\n",
    "        splits = ['train', 'validation', 'test']\n",
    "        train_ds, val_ds, test_ds = tfds.load(\n",
    "            'chest_xray',\n",
    "            split=splits,\n",
    "            as_supervised=True,\n",
    "        )\n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dda2a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = load_dataset(DATASET_NAME)\n",
    "print(train_ds, val_ds, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f345ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "train_ds = train_ds.map(preprocess).shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds   = val_ds.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds  = test_ds.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8bc676",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014bb69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, epochs=EPOCHS, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e347387",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print(f'Precisión en datos de prueba: {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea2b7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Validación')\n",
    "plt.legend()\n",
    "plt.title('Precisión por época')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86b3f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fname in uploaded.keys():\n",
    "    img = tf.keras.preprocessing.image.load_img(fname, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0) / 255.0\n",
    "    prediction = model.predict(img_array)[0][0]\n",
    "    label = 'Positivo' if prediction > 0.5 else 'Negativo'\n",
    "    print(f\"{fname}: {label} ({prediction:.2f})\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
